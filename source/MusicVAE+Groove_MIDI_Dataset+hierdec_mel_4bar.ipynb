{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency Error = Version compatibility problem\n",
        "\n",
        "\n",
        "\n",
        "=== magenta/magenta/version.py ===\n",
        "\n",
        "__version__ = '2.1.4'"
      ],
      "metadata": {
        "id": "hlHhfSiuBjFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 셀 실행 후 런타임 다시 시작 \n",
        "!pip install magenta==2.1.4"
      ],
      "metadata": {
        "id": "C9KjwoU_BedV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68166ff6-cd14-4ec5-e4cd-d2e19f2e54c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting magenta==2.1.4\n",
            "  Downloading magenta-2.1.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 34.5 MB/s \n",
            "\u001b[?25hCollecting dm-sonnet==2.0.0\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 96.1 MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 79.8 MB/s \n",
            "\u001b[?25hCollecting imageio==2.20.0\n",
            "  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 57.1 MB/s \n",
            "\u001b[?25hCollecting pygtrie==2.5.0\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tensorflow-probability==0.17.0 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.4) (0.17.0)\n",
            "Collecting absl-py==1.2.0\n",
            "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 90.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.4) (1.7.3)\n",
            "Collecting pretty-midi==0.2.9\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 82.7 MB/s \n",
            "\u001b[?25hCollecting sox==1.4.1\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting mir-eval==0.7\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting python-rtmidi==1.1.2\n",
            "  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)\n",
            "\u001b[K     |████████████████████████████████| 204 kB 87.3 MB/s \n",
            "\u001b[?25hCollecting sk-video==1.1.10\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 75.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 28 kB/s \n",
            "\u001b[?25hCollecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.4) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-datasets==4.6.0 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.4) (4.6.0)\n",
            "Collecting wheel==0.37.1\n",
            "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Collecting numba==0.49.1\n",
            "  Downloading numba-0.49.1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 90.5 MB/s \n",
            "\u001b[?25hCollecting mido==1.2.6\n",
            "  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting tf-slim==1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 39 kB/s \n",
            "\u001b[?25hCollecting matplotlib==3.5.2\n",
            "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 88.5 MB/s \n",
            "\u001b[?25hCollecting note-seq==0.0.3\n",
            "  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 99.2 MB/s \n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 82.7 MB/s \n",
            "\u001b[?25hCollecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 86.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet==2.0.0->magenta==2.1.4) (0.8.10)\n",
            "Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet==2.0.0->magenta==2.1.4) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet==2.0.0->magenta==2.1.4) (1.14.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta==2.1.4) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta==2.1.4) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta==2.1.4) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 85.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta==2.1.4) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta==2.1.4) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta==2.1.4) (2.8.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from mir-eval==0.7->magenta==2.1.4) (0.16.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (2.1.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (7.9.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (1.3.5)\n",
            "Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (2.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (3.19.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from note-seq==0.0.3->magenta==2.1.4) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.49.1->magenta==2.1.4) (57.4.0)\n",
            "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
            "  Downloading llvmlite-0.32.1-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 86.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->magenta==2.1.4) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->magenta==2.1.4) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->magenta==2.1.4) (2.8.8)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (0.28.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.1->magenta==2.1.4) (3.3.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (2.23.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (5.10.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (0.10.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (4.64.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (1.12.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.6.0->magenta==2.1.4) (2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.17.0->magenta==2.1.4) (1.5.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq==0.0.3->magenta==2.1.4) (6.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq==0.0.3->magenta==2.1.4) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq==0.0.3->magenta==2.1.4) (6.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from intervaltree>=2.1.0->note-seq==0.0.3->magenta==2.1.4) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh>=0.12.0->note-seq==0.0.3->magenta==2.1.4) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.18.1->note-seq==0.0.3->magenta==2.1.4) (2022.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta==2.1.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta==2.1.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta==2.1.4) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta==2.1.4) (1.24.3)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 83.3 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 82.3 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 82.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->magenta==2.1.4) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.9.0->librosa==0.7.2->magenta==2.1.4) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->magenta==2.1.4) (2.21)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta==2.1.4) (3.2.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 84.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq==0.0.3->magenta==2.1.4) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->note-seq==0.0.3->magenta==2.1.4) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->note-seq==0.0.3->magenta==2.1.4) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->note-seq==0.0.3->magenta==2.1.4) (0.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.6.0->magenta==2.1.4) (1.57.0)\n",
            "Building wheels for collected packages: librosa, mir-eval, pretty-midi, python-rtmidi\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612903 sha256=70c97597e2ddb05497055a297fdeefb551324b849d08b50aac683a62e27a08ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100720 sha256=e4c5aab20fcb3e314d4fb7683f00668ddaacc05cc1b82a8e57617719d2afcbc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/53/83/1d50d15a666140d53eda589db005f7cb53b739c7e54711f51f\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591954 sha256=714d4342bd0937a446c964aeb967c1f111bb8870856aafa0faaa618e246c8174\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp38-cp38-linux_x86_64.whl size=417589 sha256=255fd2f1520c1154bca6317ab6e79b11ad30bd6fd23fd484fe578c42db39d2fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/93/e9/7d805b982c4cb5c6cec3e77e1fc6e7417a193beca2230cea52\n",
            "Successfully built librosa mir-eval pretty-midi python-rtmidi\n",
            "Installing collected packages: six, llvmlite, numba, wheel, resampy, Pillow, mido, jedi, absl-py, pydub, pretty-midi, librosa, imageio, fonttools, tf-slim, tensorflow, sox, sk-video, scikit-image, python-rtmidi, pygtrie, note-seq, mir-eval, matplotlib, dm-sonnet, magenta\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.38.4\n",
            "    Uninstalling wheel-0.38.4:\n",
            "      Successfully uninstalled wheel-0.38.4\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.2\n",
            "    Uninstalling resampy-0.4.2:\n",
            "      Successfully uninstalled resampy-0.4.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed Pillow-9.2.0 absl-py-1.2.0 dm-sonnet-2.0.0 fonttools-4.38.0 imageio-2.20.0 jedi-0.18.2 librosa-0.7.2 llvmlite-0.32.1 magenta-2.1.4 matplotlib-3.5.2 mido-1.2.6 mir-eval-0.7 note-seq-0.0.3 numba-0.49.1 pretty-midi-0.2.9 pydub-0.25.1 pygtrie-2.5.0 python-rtmidi-1.1.2 resampy-0.3.1 scikit-image-0.19.3 six-1.16.0 sk-video-1.1.10 sox-1.4.1 tensorflow-2.9.1 tf-slim-1.1.0 wheel-0.37.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn2EvgaWca6s",
        "outputId": "04408ae3-bf8e-4e2e-e81b-98e88c509d3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "gHPAcGtiCSs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "-guTbmhAqwK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import zipfile \n",
        "import os\n",
        "import pandas as pd\n",
        "import IPython\n",
        "import collections\n",
        "import note_seq \n",
        "\n",
        "from magenta.common import merge_hparams\n",
        "from magenta.contrib import training as contrib_training\n",
        "from magenta.models.music_vae import MusicVAE\n",
        "from magenta.models.music_vae import lstm_models\n",
        "from magenta.models.music_vae import data\n",
        "from magenta.scripts.convert_dir_to_note_sequences import convert_directory , convert_midi \n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim \n",
        "#TF-Slim은 저수준의 텐서플로우 API를 간편하게 사용할 수 있는 고수준 경량 API"
      ],
      "metadata": {
        "id": "foxKfBpnCKKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45282749-2435-4f90-f61b-0a2cfffa71b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.8/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make dataset "
      ],
      "metadata": {
        "id": "iW5sRH3wC5uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data"
      ],
      "metadata": {
        "id": "fMZTZ5pbC94I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# groove-v1.0.0-midionly.zip\n",
        "# !gdown 1TVJgOECJ-f_a1AK8HNfB9GDXxY0ssQcr\n",
        "\n",
        "# groove-v1.0.0-midionly_over_2bar.zip\n",
        "!gdown 1JV2IryZOZJmjSisdxGk6iaq0Di6YulDm"
      ],
      "metadata": {
        "id": "hvHVpYC1CW9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcf6b93-2c15-45d8-c6f3-7a78df1a25e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JV2IryZOZJmjSisdxGk6iaq0Di6YulDm\n",
            "To: /content/groove-v1.0.0-midionly_over_2bar.zip\n",
            "\r  0% 0.00/3.00M [00:00<?, ?B/s]\r100% 3.00M/3.00M [00:00<00:00, 291MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make directory\n",
        "!mkdir data_dir"
      ],
      "metadata": {
        "id": "2v-N9uJdqJif"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip파일 압축해제 \n",
        "with zipfile.ZipFile('./groove-v1.0.0-midionly_over_2bar.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data_dir')"
      ],
      "metadata": {
        "id": "ZERl15psAixP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#경로지정 - convert_directory\n",
        "\n",
        "# 압축해제된 데이터 경로 \n",
        "root_dir = '/content/data_dir/groove-v1.0.0-midionly_over_2bar/groove' \n",
        "# MIDI 파일을 TFrecord로 변환한 파일 경로 \n",
        "output_file = '/content/data_dir/sequence.tfrecord'\n"
      ],
      "metadata": {
        "id": "mkEMDo0gDUQ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIDI파일 정보 확인 \n",
        "df = pd.read_csv('/content/data_dir/groove-v1.0.0-midionly_over_2bar/groove/info.csv')\n",
        "df = pd.DataFrame(df)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Zgc8w65GDVOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "86304017-de0b-4433-910f-429b1426560d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    drummer                session                        id           style  \\\n",
              "0  drummer1  drummer1/eval_session   drummer1/eval_session/1    funk/groove1   \n",
              "1  drummer1  drummer1/eval_session  drummer1/eval_session/10   soul/groove10   \n",
              "2  drummer1  drummer1/eval_session   drummer1/eval_session/2    funk/groove2   \n",
              "3  drummer1  drummer1/eval_session   drummer1/eval_session/3    soul/groove3   \n",
              "4  drummer1  drummer1/eval_session   drummer1/eval_session/4    soul/groove4   \n",
              "5  drummer1  drummer1/eval_session   drummer1/eval_session/5    funk/groove5   \n",
              "6  drummer1  drummer1/eval_session   drummer1/eval_session/6  hiphop/groove6   \n",
              "7  drummer1  drummer1/eval_session   drummer1/eval_session/7     pop/groove7   \n",
              "8  drummer1  drummer1/eval_session   drummer1/eval_session/8    rock/groove8   \n",
              "9  drummer1  drummer1/eval_session   drummer1/eval_session/9    soul/groove9   \n",
              "\n",
              "   bpm beat_type time_signature  \\\n",
              "0  138      beat            4-4   \n",
              "1  102      beat            4-4   \n",
              "2  105      beat            4-4   \n",
              "3   86      beat            4-4   \n",
              "4   80      beat            4-4   \n",
              "5   84      beat            4-4   \n",
              "6   87      beat            4-4   \n",
              "7  138      beat            4-4   \n",
              "8   65      beat            4-4   \n",
              "9  105      beat            4-4   \n",
              "\n",
              "                                       midi_filename  \\\n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
              "5  drummer1/eval_session/5_funk-groove5_84_beat_4...   \n",
              "6  drummer1/eval_session/6_hiphop-groove6_87_beat...   \n",
              "7  drummer1/eval_session/7_pop-groove7_138_beat_4...   \n",
              "8  drummer1/eval_session/8_rock-groove8_65_beat_4...   \n",
              "9  drummer1/eval_session/9_soul-groove9_105_beat_...   \n",
              "\n",
              "                                      audio_filename   duration split  \n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  \n",
              "5  drummer1/eval_session/5_funk-groove5_84_beat_4...  45.687518  test  \n",
              "6  drummer1/eval_session/6_hiphop-groove6_87_beat...  44.119242  test  \n",
              "7  drummer1/eval_session/7_pop-groove7_138_beat_4...  27.706547  test  \n",
              "8  drummer1/eval_session/8_rock-groove8_65_beat_4...  59.067313  test  \n",
              "9  drummer1/eval_session/9_soul-groove9_105_beat_...  36.540504  test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-114fa3f3-d603-4e42-91b1-d2d3a8d911c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drummer</th>\n",
              "      <th>session</th>\n",
              "      <th>id</th>\n",
              "      <th>style</th>\n",
              "      <th>bpm</th>\n",
              "      <th>beat_type</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>midi_filename</th>\n",
              "      <th>audio_filename</th>\n",
              "      <th>duration</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/1</td>\n",
              "      <td>funk/groove1</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>27.872308</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/10</td>\n",
              "      <td>soul/groove10</td>\n",
              "      <td>102</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>37.691158</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/2</td>\n",
              "      <td>funk/groove2</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>36.351218</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/3</td>\n",
              "      <td>soul/groove3</td>\n",
              "      <td>86</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>44.716543</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/4</td>\n",
              "      <td>soul/groove4</td>\n",
              "      <td>80</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>47.987500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/5</td>\n",
              "      <td>funk/groove5</td>\n",
              "      <td>84</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/5_funk-groove5_84_beat_4...</td>\n",
              "      <td>drummer1/eval_session/5_funk-groove5_84_beat_4...</td>\n",
              "      <td>45.687518</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/6</td>\n",
              "      <td>hiphop/groove6</td>\n",
              "      <td>87</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/6_hiphop-groove6_87_beat...</td>\n",
              "      <td>drummer1/eval_session/6_hiphop-groove6_87_beat...</td>\n",
              "      <td>44.119242</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/7</td>\n",
              "      <td>pop/groove7</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/7_pop-groove7_138_beat_4...</td>\n",
              "      <td>drummer1/eval_session/7_pop-groove7_138_beat_4...</td>\n",
              "      <td>27.706547</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/8</td>\n",
              "      <td>rock/groove8</td>\n",
              "      <td>65</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/8_rock-groove8_65_beat_4...</td>\n",
              "      <td>drummer1/eval_session/8_rock-groove8_65_beat_4...</td>\n",
              "      <td>59.067313</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/9</td>\n",
              "      <td>soul/groove9</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/9_soul-groove9_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/9_soul-groove9_105_beat_...</td>\n",
              "      <td>36.540504</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-114fa3f3-d603-4e42-91b1-d2d3a8d911c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-114fa3f3-d603-4e42-91b1-d2d3a8d911c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-114fa3f3-d603-4e42-91b1-d2d3a8d911c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 총 갯수 \n",
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Afjep76Mx4p",
        "outputId": "19a8202a-f2d2-4410-d11f-70af725d98e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1150"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert MIDI directory to TFrecord "
      ],
      "metadata": {
        "id": "IGLyHjIdDYY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == magenta/scripts/convert_dir_to_note_sequences.py == \n",
        "# == convert_directory 사용 == \n",
        "\n",
        "convert_directory(root_dir,output_file,recursive=True) "
      ],
      "metadata": {
        "id": "8vUTrZ63DcPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee1f408-c6ff-45fb-cb5c-d3b15609f293"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to find a converter for file /content/data_dir/groove-v1.0.0-midionly_over_2bar/groove/README\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/data_dir/groove-v1.0.0-midionly_over_2bar/groove/info.csv\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/data_dir/groove-v1.0.0-midionly_over_2bar/groove/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "Psm19Z0_sRW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == magenta/models/music_vae/configs.py == \n",
        "\n",
        "\n",
        "class Config(collections.namedtuple(\n",
        "    'Config',\n",
        "    ['model', 'hparams', 'note_sequence_augmenter', 'data_converter',\n",
        "     'train_examples_path', 'eval_examples_path', 'tfds_name'])):\n",
        "\n",
        "    def values(self):\n",
        "        return self._asdict()\n",
        "\n",
        "Config.__new__.__defaults__ = (None,) * len(Config._fields)\n",
        "\n",
        "\n",
        "def update_config(config, update_dict):\n",
        "    config_dict = config.values()\n",
        "    config_dict.update(update_dict)\n",
        "    return Config(**config_dict)\n",
        "\n",
        "\n",
        "CONFIG_MAP = {}\n",
        "\n",
        "\n",
        "HParams = contrib_training.HParams\n",
        "\n",
        "\n",
        "CONFIG_MAP['hierdec-mel_16bar'] = Config(\n",
        "    model=MusicVAE(\n",
        "        lstm_models.BidirectionalLstmEncoder(),\n",
        "        lstm_models.HierarchicalLstmDecoder(\n",
        "            lstm_models.CategoricalLstmDecoder(),\n",
        "            level_lengths=[16, 4],\n",
        "            disable_autoregression=True)),\n",
        "    hparams=merge_hparams(\n",
        "        lstm_models.get_default_hparams(),\n",
        "        HParams(\n",
        "            batch_size=512,\n",
        "            max_seq_len= 16*4,\n",
        "            z_size=512,\n",
        "            enc_rnn_size=[2048, 2048],\n",
        "            dec_rnn_size=[1024, 1024],\n",
        "            free_bits=256,\n",
        "            max_beta=0.2, \n",
        "            learning_rate = 0.001, # Learning rate \n",
        "            decay_rata = 0.9999, # Learning rate decay per minibatch\n",
        "            min_learning_rate = 0.00001 \n",
        "        )),\n",
        "    note_sequence_augmenter=None,\n",
        "    data_converter=data.GrooveConverter(\n",
        "        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
        "        max_tensors_per_notesequence=20,\n",
        "        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
        "\n",
        "        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
        "    # train data 경로 설정 \n",
        "    train_examples_path='/content/data_dir/sequence.tfrecord'\n",
        ")"
      ],
      "metadata": {
        "id": "F-Yh5vf3sS9A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # GrooVAE configs\n",
        "\n",
        "# CONFIG_MAP['groovae_4bar'] = Config(\n",
        "#     model=MusicVAE(lstm_models.BidirectionalLstmEncoder(), # BidirectionalLstmEncoder\n",
        "#                    lstm_models.GrooveLstmDecoder()), # Groove LSTM Decoder with MSE loss for continuous values\n",
        "#     hparams=merge_hparams(\n",
        "#         lstm_models.get_default_hparams(),\n",
        "#         HParams(\n",
        "#             batch_size=512, # Minibatch size\n",
        "#             max_seq_len= 16 * 4,  # 4 bars with 16 steps per bar \n",
        "#             z_size= 256, # Size of latent vector  \n",
        "#             enc_rnn_size=[512, 512], # Size of Encoder\n",
        "#             dec_rnn_size=[256, 256],# Size of decoder\n",
        "#             max_beta=0.2, # Maximum KL cost weight, or cost if not annealing\n",
        "#             free_bits= 48, # Bits to exclude from KL loss per dimension\n",
        "#             dropout_keep_prob=0.3, \n",
        "#             learning_rate = 0.001, # Learning rate \n",
        "#             decay_rata = 0.9999, # Learning rate decay per minibatch\n",
        "#             min_learning_rate = 0.00001 , \n",
        "#         )),\n",
        "#     note_sequence_augmenter=None,\n",
        "#     data_converter=data.GrooveConverter(\n",
        "#         split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
        "#         max_tensors_per_notesequence=20,\n",
        "#         pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
        "\n",
        "#         inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
        "#     # train data 경로 설정 \n",
        "#     train_examples_path='/content/data_dir/sequence.tfrecord')"
      ],
      "metadata": {
        "id": "2kNG2AeFgnjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train "
      ],
      "metadata": {
        "id": "j6AQO2cXsVm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#============ License=====================================================\n",
        "# Copyright 2022 The Magenta Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "#=======================================================================\n",
        "\n",
        "#=== MusicVAE train script===\n",
        "#== magenta/models/music_vae/music_vae_train.py ==\n",
        "\n",
        "# Should not be called from within the graph to avoid redundant summaries.\n",
        "def _trial_summary(hparams, examples_path, output_dir):\n",
        "     #=== Writes a tensorboard text summary of the trial===\n",
        "\n",
        "    examples_path_summary = tf.summary.text(\n",
        "        'examples_path', tf.constant(examples_path, name='examples_path'),\n",
        "        collections=[])\n",
        "\n",
        "    hparams_dict = hparams.values()\n",
        "\n",
        "#===  Create a markdown table from hparams ===\n",
        "    header = '| Key | Value |\\n| :--- | :--- |\\n'\n",
        "    keys = sorted(hparams_dict.keys())\n",
        "    lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n",
        "    hparams_table = header + '\\n'.join(lines) + '\\n'\n",
        "\n",
        "    hparam_summary = tf.summary.text(\n",
        "        'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n",
        "        writer.add_summary(examples_path_summary.eval())\n",
        "        writer.add_summary(hparam_summary.eval())\n",
        "        writer.close()\n",
        "\n",
        "\n",
        "def _get_input_tensors(dataset, config):\n",
        "    #== Get input tensors from dataset ===\n",
        "    batch_size = config.hparams.batch_size\n",
        "    iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "    (input_sequence, output_sequence, control_sequence,sequence_length) = iterator.get_next()\n",
        "    input_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.input_depth])\n",
        "    output_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.output_depth])\n",
        "    \n",
        "    if not config.data_converter.control_depth:\n",
        "        control_sequence = None\n",
        "    \n",
        "    else:\n",
        "        control_sequence.set_shape(\n",
        "            [batch_size, None, config.data_converter.control_depth])\n",
        "    sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "        \n",
        "    return {\n",
        "        'input_sequence': input_sequence,\n",
        "        'output_sequence': output_sequence,\n",
        "        'control_sequence': control_sequence,\n",
        "        'sequence_length': sequence_length\n",
        "    }\n",
        "\n",
        "#=== Set Training checkpoints and hours ===\n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep= 5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "\n",
        "#==== Train loop ====\n",
        "    tf.gfile.MakeDirs(train_dir)\n",
        "    is_chief = (task == 0)\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "        with tf.device(tf.train.replica_device_setter(\n",
        "                num_ps_tasks, merge_devices=True)):\n",
        "            \n",
        "            model = config.model\n",
        "            model.build(config.hparams,\n",
        "                        config.data_converter.output_depth,\n",
        "                        is_training=True)\n",
        "            #== Optimizer ===\n",
        "            optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "            hooks = []\n",
        "            if num_sync_workers:\n",
        "                optimizer = tf.train.SyncReplicasOptimizer(\n",
        "                    optimizer,num_sync_workers)\n",
        "                hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "            grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n",
        "            global_norm = tf.global_norm(grads)\n",
        "            tf.summary.scalar('global_norm', global_norm)\n",
        "            \n",
        "            if config.hparams.clip_mode == 'value':\n",
        "                g = config.hparams.grad_clip\n",
        "                clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "            elif config.hparams.clip_mode == 'global_norm':\n",
        "                clipped_grads = tf.cond(\n",
        "                    global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "                    lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                        grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "                    lambda: [tf.zeros(tf.shape(g)) for g in grads])\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n",
        "            train_op = optimizer.apply_gradients(\n",
        "                list(zip(clipped_grads, var_list)),\n",
        "                global_step=model.global_step,\n",
        "                name='train_step')\n",
        "\n",
        "            logging_dict = {'global_step': model.global_step,\n",
        "                            'loss': model.loss}\n",
        "            \n",
        "            hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "            if num_steps:\n",
        "                hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "                \n",
        "            scaffold = tf.train.Scaffold(\n",
        "                saver=tf.train.Saver(\n",
        "                    max_to_keep=checkpoints_to_keep,\n",
        "                    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n",
        "            \n",
        "            tf_slim.training.train(\n",
        "                train_op=train_op,\n",
        "                logdir=train_dir,\n",
        "                scaffold=scaffold,\n",
        "                hooks=hooks,\n",
        "                save_checkpoint_secs=60,\n",
        "                master=master,\n",
        "                is_chief=is_chief)\n",
        "\n",
        "\n",
        "def run(config_map,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        file_reader=tf.python_io.tf_record_iterator,\n",
        "        is_training=True):\n",
        "  # Load model params, save config file and start trainer\n",
        "    config = config_map['hierdec-mel_4bar']\n",
        "    train_dir = '/content/train'\n",
        "    num_steps = 10000  #epoch\n",
        "    \n",
        "    def dataset_fn():\n",
        "        return data.get_dataset(\n",
        "            config,\n",
        "            tf_file_reader=tf_file_reader,\n",
        "            is_training=True,\n",
        "            cache_dataset=True)\n",
        "    \n",
        "    if is_training == True:\n",
        "        train(\n",
        "            train_dir,\n",
        "            config=config,\n",
        "            dataset_fn=dataset_fn,\n",
        "            checkpoints_to_keep = 5,\n",
        "            keep_checkpoint_every_n_hours = 1,\n",
        "            num_steps=num_steps)      \n",
        "  \n",
        "    else:\n",
        "        print(\"Training is False\")"
      ],
      "metadata": {
        "id": "LKpI8VcUsWxX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(CONFIG_MAP) #epoch 10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwSqr3HIuHSJ",
        "outputId": "88cb6bcd-e20d-4c52-b9e5-1ea3df3161d6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:463: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  self._kernel = self.add_variable(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  self._bias = self.add_variable(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  mu = tf.layers.dense(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  sigma = tf.layers.dense(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  tf.layers.dense(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate"
      ],
      "metadata": {
        "id": "S7SvsSkTuKin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir generated_midi"
      ],
      "metadata": {
        "id": "q2VoleDkuJO5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=== magenta/magenta/models/music_vae/music_vae_generate.py ===\n",
        "model = TrainedModel(\n",
        "    config = CONFIG_MAP['hierdec-mel_4bar'],\n",
        "    batch_size = 32, # min(max_batch_size, num_outputs)\n",
        "    checkpoint_dir_or_path='/content/train') # 체크포인트의 경로\n",
        "\n",
        "drum_samples = model.sample(n=1, length=16*4, temperature=0.5)\n",
        "note_seq.sequence_proto_to_midi_file(drum_samples[0], '/content/generated_midi/hierdec-mel_4bar_32.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9q_yIu2uNXz",
        "outputId": "4c28fca3-7d68-4a2b-95bd-579e2736f6b6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDP33XVxxK6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}